{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhA9hlayAvgn",
        "outputId": "af8bf55c-f090-4ecb-a83f-4284675ddb8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Replace 'your_path' with the path where you saved Gesture.zip in Google Drive, or upload directly to Colab.\n",
        "# Example path for files on Google Drive: '/content/drive/MyDrive/path_to_files/gesture/train.pt'\n",
        "train_path = '/content/drive/MyDrive/Gesture/train.pt'\n",
        "val_path = '/content/drive/MyDrive/Gesture/val.pt'\n",
        "test_path = '/content/drive/MyDrive/Gesture/test.pt'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFqZED9K7Qv6",
        "outputId": "b2f20c86-f185-4f36-8562-1bccb35a6c8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "CZ8kn_2T7Vg9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A91ycmNu7xfb",
        "outputId": "dccbf6ed-eb4a-4da9-ff11-3aee3455e03b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-b80679d3d9da>:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  train_data = torch.load(train_path)\n",
            "<ipython-input-4-b80679d3d9da>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  val_data = torch.load(val_path)\n",
            "<ipython-input-4-b80679d3d9da>:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  test_data = torch.load(test_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data batch shape: torch.Size([32, 3, 206])\n",
            "Label batch shape: torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load the .pt files\n",
        "train_data = torch.load(train_path)\n",
        "val_data = torch.load(val_path)\n",
        "test_data = torch.load(test_path)\n",
        "\n",
        "# Extract features (samples) and labels\n",
        "X_train = train_data['samples']\n",
        "y_train = train_data['labels']\n",
        "X_val = val_data['samples']\n",
        "y_val = val_data['labels']\n",
        "X_test = test_data['samples']\n",
        "y_test = test_data['labels']\n",
        "\n",
        "# Convert data to float32 and labels to long for PyTorch compatibility\n",
        "X_train = X_train.float()\n",
        "y_train = y_train.long()\n",
        "X_val = X_val.float()\n",
        "y_val = y_val.long()\n",
        "X_test = X_test.float()\n",
        "y_test = y_test.long()\n",
        "\n",
        "# Impute missing values with the mean for each feature\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_train_imputed = torch.tensor(imputer.fit_transform(X_train.view(X_train.shape[0], -1).numpy()), dtype=torch.float32).view(X_train.shape)\n",
        "X_val_imputed = torch.tensor(imputer.transform(X_val.view(X_val.shape[0], -1).numpy()), dtype=torch.float32).view(X_val.shape)\n",
        "X_test_imputed = torch.tensor(imputer.transform(X_test.view(X_test.shape[0], -1).numpy()), dtype=torch.float32).view(X_test.shape)\n",
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = torch.tensor(scaler.fit_transform(X_train_imputed.view(X_train_imputed.shape[0], -1).numpy()), dtype=torch.float32).view(X_train_imputed.shape)\n",
        "X_val_scaled = torch.tensor(scaler.transform(X_val_imputed.view(X_val_imputed.shape[0], -1).numpy()), dtype=torch.float32).view(X_val_imputed.shape)\n",
        "X_test_scaled = torch.tensor(scaler.transform(X_test_imputed.view(X_test_imputed.shape[0], -1).numpy()), dtype=torch.float32).view(X_test_imputed.shape)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_dataset = TensorDataset(X_train_scaled, y_train)\n",
        "val_dataset = TensorDataset(X_val_scaled, y_val)\n",
        "test_dataset = TensorDataset(X_test_scaled, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "# Optional: Check DataLoader outputs\n",
        "for data, label in train_loader:\n",
        "    print(\"Data batch shape:\", data.shape)\n",
        "    print(\"Label batch shape:\", label.shape)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FfVaplBV9niS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SelfSupervisedModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SelfSupervisedModel, self).__init__()\n",
        "        # Update the in_channels of the first conv layer to 3\n",
        "        self.conv1 = nn.Conv1d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(32 * 206, 128)  # Flattened size adjustment\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = nn.functional.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = nn.functional.relu(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten before passing to fully connected layers\n",
        "        x = self.fc1(x)\n",
        "        x = nn.functional.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWIlHeqv91mJ",
        "outputId": "2496355b-4a3f-4657-b803-c83b87b87068"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.0171\n",
            "Epoch [2/5], Loss: 0.0006\n",
            "Epoch [3/5], Loss: 0.0003\n",
            "Epoch [4/5], Loss: 0.0002\n",
            "Epoch [5/5], Loss: 0.0001\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Initialize model, criterion, and optimizer\n",
        "model = SelfSupervisedModel()\n",
        "criterion = nn.CosineEmbeddingLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)  # Added scheduler\n",
        "\n",
        "# Self-supervised pre-training (extended to 20 epochs)\n",
        "pretrain_epochs = 5\n",
        "for epoch in range(pretrain_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for batch_idx, (data, _) in enumerate(train_loader):\n",
        "        # Separate positive and negative pairs\n",
        "        pos_pair = data\n",
        "        neg_pair = data[torch.randperm(data.size(0))]  # Random shuffling to create negatives\n",
        "\n",
        "        # Ensure target size matches batch size\n",
        "        target = torch.ones(pos_pair.size(0), device=data.device)  # Positive labels for CosineEmbeddingLoss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        output_pos = model(pos_pair)\n",
        "        output_neg = model(neg_pair)\n",
        "\n",
        "        # Compute CosineEmbeddingLoss\n",
        "        loss = criterion(output_pos, output_neg, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Step the learning rate scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{pretrain_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84p9NHDKdQFK",
        "outputId": "34266f0f-8f6d-46d4-a821-cb7ca7d82b20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YourModel(\n",
            "  (conv1): Conv1d(3, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "  (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=13184, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define your model class with dynamic calculation of the flattened dimension\n",
        "class YourModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(YourModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(3, 64, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv1d(64, 64, kernel_size=3, padding=1)\n",
        "        self.dropout = nn.Dropout(p=0.5)  # Dropout for regularization\n",
        "\n",
        "        # Calculate the flattened dimension\n",
        "        sample_input = torch.randn(1, 3, 206)  # Sample input with your data's dimensions\n",
        "        flattened_dim = self._get_flattened_dim(sample_input)\n",
        "\n",
        "        # Define the fully connected layer with correct input size\n",
        "        self.fc = nn.Linear(flattened_dim, 10)  # Assuming 10 output classes\n",
        "\n",
        "    def _get_flattened_dim(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
        "        return x.size(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten for fully connected layer\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate and check the model\n",
        "model = YourModel()\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMndxqTS_Kip",
        "outputId": "379b09a1-c810-4e53-b1a8-732fe74bb429"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Train Loss: 0.6530, Train Acc: 0.9812, Val Loss: 3.5397, Val Acc: 0.5917\n",
            "Epoch [2/50], Train Loss: 0.7269, Train Acc: 0.9781, Val Loss: 3.8861, Val Acc: 0.5833\n",
            "Epoch [3/50], Train Loss: 0.5001, Train Acc: 0.9875, Val Loss: 3.5757, Val Acc: 0.5417\n",
            "Epoch [4/50], Train Loss: 0.3913, Train Acc: 0.9875, Val Loss: 3.6619, Val Acc: 0.5583\n",
            "Epoch [5/50], Train Loss: 0.5884, Train Acc: 0.9781, Val Loss: 3.6401, Val Acc: 0.5417\n",
            "Epoch [6/50], Train Loss: 0.3672, Train Acc: 0.9875, Val Loss: 3.8715, Val Acc: 0.5833\n",
            "Early stopping triggered.\n",
            "Test Loss: 3.8715, Test Accuracy: 0.5833, Test Precision: 0.5366, Test Recall: 0.5833, Test F1: 0.5524\n"
          ]
        }
      ],
      "source": [
        "# Loss and Optimizer with Weight Decay for regularization\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "\n",
        "# DataLoader for training, validation, and test sets (modify as per your dataset)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Evaluation Function for Validation and Test\n",
        "def evaluate(model, loader):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    loss, correct, total = 0, 0, 0\n",
        "    all_labels, all_preds = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, labels in loader:\n",
        "            outputs = model(data)\n",
        "            batch_loss = criterion(outputs, labels)\n",
        "            loss += batch_loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    accuracy = correct / total\n",
        "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
        "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "    return loss / len(loader), accuracy, precision, recall, f1\n",
        "\n",
        "# Training Loop with Early Stopping\n",
        "num_epochs = 50\n",
        "best_val_loss = float('inf')\n",
        "patience, patience_counter = 5, 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set model to training mode\n",
        "    train_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    for data, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(data)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_accuracy = correct / total\n",
        "    val_loss, val_accuracy, _, _, _ = evaluate(model, val_loader)  # Only val_loss and val_accuracy are printed\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
        "\n",
        "    # Early Stopping Check\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        patience_counter = 0\n",
        "        best_model = model.state_dict()  # Save best model\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "model.load_state_dict(best_model)  # Load best model for testing\n",
        "\n",
        "# Final Testing\n",
        "test_loss, test_accuracy, test_precision, test_recall, test_f1 = evaluate(model, test_loader)\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}, Test Precision: {test_precision:.4f}, Test Recall: {test_recall:.4f}, Test F1: {test_f1:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}